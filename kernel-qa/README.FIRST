Ubuntu Hardware Compatibility Testing
======================================
Author: Manoj Iyer <manoj.iyer@canonical.com>
==============================================

Files
=====
./configure.sh: Run the first time to install all dependencies
./kernel-qa: test case driver.
./test/* : directory contains, multiple testsuites.
./test/<file>:contains single/multiple testcases.
./xrandr_cycle: Graphics test script.
./suspend_test: Suspend resume test script.

How to run the tests
=====================
Install test dependencies.
----------------------
Run ./configure.sh to install all test dependencies

Start testing.
--------------
./kernel_qa <hit enter>

This should start the main menu and you should be able to go from there. After you
run all the tests, and quit the application. The results will be available in
<unique id>.logs.tgz, this tgz file will contain the results file, and other 
related log files. kernel-qa.<Subsystem>.<testcase>.apport contains the apport
collected data on failure. 

The test driver kernel-qa is designed to read the 1st line of each testsuite in
test/* and run the functions listed there, in the order they are listed. Currently
you can skip the entire testsuite, by unselecting it in the Test menu. To re-arrange
the order in which they appear in the Test menu, rename the testsuite as 001<filename>
002<filename> ... NNN<filename>

Or you can skip individual testcases, as the test makes progress, or by 
uncommenting it in the testsuite file. You may change the order of the testcases 
by re-arranging the order in which they appear on line 1 of each testsuite file.

Test Results.
-------------
kernel-qa.testresults: contains test pass/fail information in the follwoing format.
============= kernel-qa.testresults file =======
<Subsystem>:<testcase>:<PASS/FAIL/SKIPPED>
================================================
Also, kernel-qa.<Subsystem>.<testcase>.apport contains the apport
collected data on failure.

How to write new tests
======================
NOTE: DO NOT USE TABS. I HATE TABS, USE SPACES.

Testcases go under ./tests/, currently there are audio, video, buttons, suspend/resume,
storage and graphics. You can refer to any of these file (say video) and model your test
case based on that. A general template a test case is as below, it should be pretty
obvious how to write the test if you look at the existing tests/scripts and run through
the tests. But here is a template anyway...

---------- test template for dummys -------------------
# <setup fn if any> <testfn1> <testfn2> ... <testfnN>
# dependencies: <list if any or say NONE or none >
# Add the dependencies to ./configure.sh

these ^^^^ 2 line are important, you must have them in that order in your test file.
You may have additional comments in the file following those two lines if you want. 

test01() { # you can call your test what ever you want, just remember to list them on the 
           # 1st line of this file.
     TEST="<this filename>:<some text string description>"
     # the file name is usually short one word, like audio or video
     # test description is a short sweet few words, save your writing skills for later.

     tst_promt "some text about what you are testing \ 
                and what the expected output/result is \
                and a massage asking the user to say \
                YES to run or NO to skip."

     # tst_promt() will open a dialog box with your text, and yes and no buttons.
     # the text in quotes can span multiple lines, just remember the "\" at the end of each line.

     case $? in 
     0) # in case the user says YES I want to run this test
        # $? contains 0 if the user answered YES and some value>0 if they answer NO.

        tst_msg "some message to the user that will dissapear in 2sec"
        # tst_msg() fn will print a message/instruction to the user for 2sec.

        < add additional sleep Ns in case you want to give some time to the user to grok 
          your instruction or message >
        < run some helper some helper scripts here 2>&1 1>/dev/null >
        < insert some commands here 2>&1 1>/dev/null >

        tst_prompt "ask the user if the test passed or failed ?"
        # usually the question is did you see this or that...
 
        tst_reslog $? "<subsystem>" ;;
        # this fn will update the test report with a pass or fail for this test
        # in case the user said the testfailed, apport-cli will collect apport
        # report  for the subsystem you passed in parameter#2
      *) # in case the user said NO or hit Esc key
        tst_skip ;;
        # this fn will mark the test as skipped, and move to next test.
     esac
     return
}

--------------------- end template-----------------------------
